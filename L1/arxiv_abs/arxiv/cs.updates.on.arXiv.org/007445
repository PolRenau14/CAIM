Single image superresolution has been a popular research topic in the last two decades and has recently
received a new wave of interest due to deep neural networks. In this paper, we approach this problem
from a different perspective. With respect to a downsampled low resolution image, we model a high
resolution image as a combination of two components, a deterministic component and a stochastic
component. The deterministic component can be recovered from the low-frequency signals in the
downsampled image. The stochastic component, on the other hand, contains the signals that have
little correlation with the low resolution image. We adopt two complementary methods for generating
these two components. While generative adversarial networks are used for the stochastic component,
deterministic component reconstruction is formulated as a regression problem solved using deep
neural networks. Since the deterministic component exhibits clearer local orientations, we design
novel loss functions tailored for such properties for training the deep regression network. These
two methods are first applied to the entire input image to produce two distinct high-resolution
images. Afterwards, these two images are fused together using another deep neural network that
also performs local statistical rectification, which tries to make the local statistics of the
fused image match the same local statistics of the groundtruth image. Quantitative results and
a user study indicate that the proposed method outperforms existing state-of-the-art algorithms
with a clear margin. 