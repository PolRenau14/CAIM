The knowledge of source printer can help in printed text document authentication, copyright ownership,
and provide important clues about the author of a fraudulent document along with his/her potential
means and motives. Development of automated systems for classifying printed documents based on
their source printer, using image processing techniques, is gaining a lot of attention in multimedia
forensics. Currently, state-of-the-art systems require that the font of letters present in test
documents of unknown origin must be available in those used for training the classifier. In this
work, we attempt to take the first step towards overcoming this limitation. Specifically, we introduce
a novel printer specific local texture descriptor. The highlight of our technique is the use of encoding
and regrouping strategy based on small linear-shaped structures composed of pixels having similar
intensity and gradient. The results of experiments performed on two separate datasets show that:
1) on a publicly available dataset, the proposed method outperforms state-of-the-art algorithms
for characters printed in the same font, and 2) on another dataset\footnote{Code and dataset will
be made publicly available with published version of this paper.} having documents printed in four
different fonts, the proposed method correctly classifies all test samples when sufficient training
data is available in same font setup. In addition, it outperforms state-of-the-art methods for
cross font experiments. Moreover, it reduces the confusion between the printers of same brand and
model. 