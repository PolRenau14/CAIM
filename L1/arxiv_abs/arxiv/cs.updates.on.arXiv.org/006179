Classification of very high resolution (VHR) satellite images has three major challenges: 1) inherent
low intra-class and high inter-class spectral similarities, 2) mismatching resolution of available
bands, and 3) the need to regularize noisy classification maps. Conventional methods have addressed
these challenges by adopting separate stages of image fusion, feature extraction, and post-classification
map regularization. These processing stages, however, are not jointly optimizing the classification
task at hand. In this study, we propose a single-stage framework embedding the processing stages
in a recurrent multiresolution convolutional network trained in an end-to-end manner. The feedforward
version of the network, called FuseNet, aims to match the resolution of the panchromatic and multispectral
bands in a VHR image using convolutional layers with corresponding downsampling and upsampling
operations. Contextual label information is incorporated into FuseNet by means of a recurrent
version called ReuseNet. We compared FuseNet and ReuseNet against the use of separate processing
steps for both image fusion, e.g. pansharpening and resampling through interpolation, and map
regularization such as conditional random fields. We carried out our experiments on a land cover
classification task using a Worldview-03 image of Quezon City, Philippines and the ISPRS 2D semantic
labeling benchmark dataset of Vaihingen, Germany. FuseNet and ReuseNet surpass the baseline approaches
in both quantitative and qualitative results. 