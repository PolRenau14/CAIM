We have seen much recent progress in rigid object manipulation, but interaction with deformable
objects has notably lagged behind. Due to the large configuration space of deformable objects,
solutions using traditional modelling approaches require significant engineering work. Perhaps
then, bypassing the need for explicit modelling and instead learning the control in an end-to-end
manner serves as a better approach? Despite the growing interest in the use of end-to-end robot learning
approaches, only a small amount of work has focused on their applicability to deformable object
manipulation. Moreover, due to the large amount of data needed to learn these end-to-end solutions,
an emerging trend is to learn to control policies in simulation and then transfer them over to the
real world. To-date, no work has explored whether it is possible to learn and transfer deformable
object policies. We believe that if sim-to-real methods are the way forward, then it should be possible
to learn to interact with a wide variety of objects, and not just rigid objects. In this work, we use
a combination of state-of-the-art deep reinforcement learning algorithms to solve the problem
of manipulating deformable objects (specifically cloth). We evaluate our approach on three tasks
--- folding a towel up to a mark, folding a face towel diagonally, and draping a piece of cloth over
a hanger. Our agents are fully trained in simulation with domain randomisation, and then successfully
deployed in the real world without having seen any real deformable objects. 