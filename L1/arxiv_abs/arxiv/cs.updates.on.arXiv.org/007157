A classical heuristic in software testing is to reward diversity, which implies that a higher priority
must be assigned to test cases that differ the most from those already prioritized. This approach
is commonly known as similarity-based test prioritization (SBTP) and can be realized using a variety
of techniques. The objective of our study is to investigate whether SBTP is more effective at finding
defects than random permutation, as well as determine which SBTP implementations lead to better
results. To achieve our objective, we implemented five different techniques from the literature
and conducted an experiment using the defects4j dataset, which contains 395 real faults from six
real-world open-source Java programs. Findings indicate that running the most dissimilar test
cases early in the process is largely more effective than random permutation (Vargha-Delaney A
[VDA]: 0.76-0.99 observed using normalized compression distance). No technique was found to be
superior with respect to the effectiveness. Locality-sensitive hashing was, to a small extent,
less effective than other SBTP techniques (VDA: 0.38 observed in comparison to normalized compression
distance), but its speed largely outperformed the other techniques (i.e., it was approximately
5-111 times faster). Our results bring to mind the well-known adage, "don't put all your eggs in one
basket". To effectively consume a limited testing budget, one should spread it evenly across different
parts of the system by running the most dissimilar test cases early in the testing process. 