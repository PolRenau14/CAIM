In this paper, we present a framework for Question Difficulty and Expertise Estimation (QDEE) in
Community Question Answering sites (CQAs) such as Yahoo! Answers and Stack Overflow, which tackles
a fundamental challenge in crowdsourcing: how to appropriately route and assign questions to users
with the suitable expertise. This problem domain has been the subject of much research and includes
both language-agnostic as well as language conscious solutions. We bring to bear a key language-agnostic
insight: that users gain expertise and therefore tend to ask as well as answer more difficult questions
over time. We use this insight within the popular competition (directed) graph model to estimate
question difficulty and user expertise by identifying key hierarchical structure within said
model. An important and novel contribution here is the application of "social agony" to this problem
domain. Difficulty levels of newly posted questions (the cold-start problem) are estimated by
using our QDEE framework and additional textual features. We also propose a model to route newly
posted questions to appropriate users based on the difficulty level of the question and the expertise
of the user. Extensive experiments on real world CQAs such as Yahoo! Answers and Stack Overflow data
demonstrate the improved efficacy of our approach over contemporary state-of-the-art models.
The QDEE framework also allows us to characterize user expertise in novel ways by identifying interesting
patterns and roles played by different users in such CQAs. 