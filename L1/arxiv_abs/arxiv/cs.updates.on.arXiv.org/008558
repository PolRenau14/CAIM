Trusting simulation output is crucial for Sandia's mission objectives. We rely on these simulations
to perform our high-consequence mission tasks given national treaty obligations. Other science
and modeling applications, while they may have high-consequence results, still require the strongest
levels of trust to enable using the result as the foundation for both practical applications and
future research. To this end, the computing community has developed workflow and provenance systems
to aid in both automating simulation and modeling execution as well as determining exactly how was
some output was created so that conclusions can be drawn from the data. Current approaches for workflows
and provenance systems are all at the user level and have little to no system level support making
them fragile, difficult to use, and incomplete solutions. The introduction of container technology
is a first step towards encapsulating and tracking artifacts used in creating data and resulting
insights, but their current implementation is focused solely on making it easy to deploy an application
in an isolated "sandbox" and maintaining a strictly read-only mode to avoid any potential changes
to the application. All storage activities are still using the system-level shared storage. This
project explores extending the container concept to include storage as a new container type we call
\emph{data pallets}. Data Pallets are potentially writeable, auto generated by the system based
on IO activities, and usable as a way to link the contained data back to the application and input deck
used to create it. 