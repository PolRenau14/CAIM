Biometric recognition on partial captured targets is challenging, where only several partial
observations of objects are available for matching. In this area, deep learning based methods are
widely applied to match these partial captured objects caused by occlusions, variations of postures
or just partial out of view in person re-identification and partial face recognition. However,
most current methods are not able to identify an individual in case that some parts of the object are
not obtainable, while the rest are specialized to certain constrained scenarios. To this end, we
propose a robust general framework for arbitrary biometric matching scenarios without the limitations
of alignment as well as the size of inputs. We introduce a feature post-processing step to handle
the feature maps from FCN and a dictionary learning based Spatial Feature Reconstruction (SFR)
to match different sized feature maps in this work. Moreover, the batch hard triplet loss function
is applied to optimize the model. The applicability and effectiveness of the proposed method are
demonstrated by the results from experiments on three person re-identification datasets (Market1501,
CUHK03, DukeMTMC-reID), two partial person datasets (Partial REID and Partial iLIDS) and two partial
face datasets (CASIA-NIR-Distance and Partial LFW), on which state-of-the-art performance is
ensured in comparison with several state-of-the-art approaches. The code is released online and
can be found on the website: https://github.com/lingxiao-he/Partial-Person-ReID. 