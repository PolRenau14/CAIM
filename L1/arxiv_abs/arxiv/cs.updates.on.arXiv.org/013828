Slow Feature Analysis (SFA) extracts slowly varying features from a quickly varying input signal.
It has been successfully applied to modeling the visual receptive fields of the cortical neurons.
Sufficient experimental results in neuroscience suggest that the temporal slowness principle
is a general learning principle in visual perception. In this paper, we introduce the SFA framework
to the problem of human action recognition by incorporating the discriminative information with
SFA learning and considering the spatial relationship of body parts. In particular, we consider
four kinds of SFA learning strategies, including the original unsupervised SFA (U-SFA), the supervised
SFA (S-SFA), the discriminative SFA (D-SFA), and the spatial discriminative SFA (SD-SFA), to extract
slow feature functions from a large amount of training cuboids which are obtained by random sampling
in motion boundaries. Afterward, to represent action sequences, the squared first order temporal
derivatives are accumulated over all transformed cuboids into one feature vector, which is termed
the Accumulated Squared Derivative (ASD) feature. The ASD feature encodes the statistical distribution
of slow features in an action sequence. Finally, a linear support vector machine (SVM) is trained
to classify actions represented by ASD features. We conduct extensive experiments, including
two sets of control experiments, two sets of large scale experiments on the KTH and Weizmann databases,
and two sets of experiments on the CASIA and UT-interaction databases, to demonstrate the effectiveness
of SFA for human action recognition. 