Humans as designers have quite versatile problem-solving strategies. Computer agents on the other
hand can access large scale computational resources to solve certain design problems. Hence, if
agents can learn from human behavior, a synergetic human-agent problem solving team can be created.
This paper presents an approach to extract human design strategies and implicit rules, purely from
historical human data, and use that for design generation. A two-step framework that learns to imitate
human design strategies from observation is proposed and implemented. This framework makes use
of deep learning constructs to learn to generate designs without any explicit information about
objective and performance metrics. The framework is designed to interact with the problem through
a visual interface as humans did when solving the problem. It is trained to imitate a set of human designers
by observing their design state sequences without inducing problem-specific modelling bias or
extra information about the problem. Furthermore, an end-to-end agent is developed that uses this
deep learning framework as its core in conjunction with image processing to map pixel-to-design
moves as a mechanism to generate designs. Finally, the designs generated by a computational team
of these agents are then compared to actual human data for teams solving a truss design problem. Results
demonstrates that these agents are able to create feasible and efficient truss designs without
guidance, showing that this methodology allows agents to learn effective design strategies. 