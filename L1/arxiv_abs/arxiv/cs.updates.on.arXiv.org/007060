Model reduction of high-dimensional dynamical systems alleviates computational burdens faced
in various tasks from design optimization to model predictive control. One popular model reduction
approach is based on projecting the governing equations onto a subspace spanned by basis functions
obtained from the compression of a dataset of solution snapshots. However, this method is intrusive
since the projection requires access to the system operators. Further, some systems may require
special treatment of nonlinearities to ensure computational efficiency or additional modeling
to preserve stability. In this work we propose a deep learning-based strategy for nonlinear model
reduction that is inspired by projection-based model reduction where the idea is to identify some
optimal low-dimensional representation and evolve it in time. Our approach constructs a modular
model consisting of a deep convolutional autoencoder and a modified LSTM network. The deep convolutional
autoencoder returns a low-dimensional representation in terms of coordinates on some expressive
nonlinear data-supporting manifold. The dynamics on this manifold are then modeled by the modified
LSTM network in a computationally efficient manner. An offline unsupervised training strategy
that exploits the model modularity is also developed. We demonstrate our model on three illustrative
examples each highlighting the model's performance in prediction tasks for systems with large
parameter-variations and its stability in long-term prediction. 