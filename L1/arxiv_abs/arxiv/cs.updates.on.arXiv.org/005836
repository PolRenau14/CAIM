This paper strives for spatio-temporal localization of human actions in videos. In the literature,
the consensus is to achieve localization by training on bounding box annotations provided for each
frame of each training video. As annotating boxes in video is expensive, cumbersome and error-prone,
we propose to bypass box-supervision. Instead, we introduce action localization based on point-supervision.
We start from unsupervised spatio-temporal proposals, which provide a set of candidate regions
in videos. While normally used exclusively for inference, we show spatio-temporal proposals can
also be leveraged during training when guided by a sparse set of point annotations. We introduce
an overlap measure between points and spatio-temporal proposals and incorporate them all into
a new objective of a Multiple Instance Learning optimization. During inference, we introduce pseudo-points,
visual cues from videos, that automatically guide the selection of spatio-temporal proposals.
We outline five spatial and one temporal pseudo-point, as well as a measure to best leverage pseudo-points
at test time. Experimental evaluation on three action localization datasets shows our pointly-supervised
approach (i) is as effective as traditional box-supervision at a fraction of the annotation cost,
(ii) is robust to sparse and noisy point annotations, (iii) benefits from pseudo-points during
inference, and (iv) outperforms recent weakly-supervised alternatives. This leads us to conclude
that points provide a viable alternative to boxes for action localization. 