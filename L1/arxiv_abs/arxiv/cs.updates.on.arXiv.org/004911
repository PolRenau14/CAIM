This paper presents a novel unsupervised segmentation method for 3D medical images. Convolutional
neural networks (CNNs) have brought significant advances in image segmentation. However, most
of the recent methods rely on supervised learning, which requires large amounts of manually annotated
data. Thus, it is challenging for these methods to cope with the growing amount of medical images.
This paper proposes a unified approach to unsupervised deep representation learning and clustering
for segmentation. Our proposed method consists of two phases. In the first phase, we learn deep feature
representations of training patches from a target image using joint unsupervised learning (JULE)
that alternately clusters representations generated by a CNN and updates the CNN parameters using
cluster labels as supervisory signals. We extend JULE to 3D medical images by utilizing 3D convolutions
throughout the CNN architecture. In the second phase, we apply k-means to the deep representations
from the trained CNN and then project cluster labels to the target image in order to obtain the fully
segmented image. We evaluated our methods on three images of lung cancer specimens scanned with
micro-computed tomography (micro-CT). The automatic segmentation of pathological regions in
micro-CT could further contribute to the pathological examination process. Hence, we aim to automatically
divide each image into the regions of invasive carcinoma, noninvasive carcinoma, and normal tissue.
Our experiments show the potential abilities of unsupervised deep representation learning for
medical image segmentation. 