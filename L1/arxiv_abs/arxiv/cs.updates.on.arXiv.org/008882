Person re-identification is to retrieval pedestrian images from no-overlap camera views detected
by pedestrian detectors. Most existing person re-identification (re-ID) models often fail to
generalize well from the source domain where the models are trained to a new target domain without
labels, because of the bias between the source and target domain. This issue significantly limits
the scalability and usability of the models in the real world. Providing a labeled source training
set and an unlabeled target training set, the aim of this paper is to improve the generalization ability
of re-ID models to the target domain. To this end, we propose an image generative network named identity
preserving generative adversarial network (IPGAN). The proposed method has two excellent properties:
1) only a single model is employed to translate the labeled images from the source domain to the target
camera domains in an unsupervised manner; 2) The identity information of images from the source
domain is preserved before and after translation. Furthermore, we propose IBN-reID model for the
person re-identification task. It has better generalization ability than baseline models, especially
in the cases without any domain adaptation. The IBN-reID model is trained on the translated images
by supervised methods. Experimental results on Market-1501 and DukeMTMC-reID show that the images
generated by IPGAN are more suitable for cross-domain person re-identification. Very competitive
re-ID accuracy is achieved by our method. 