Automatic drum transcription, a subtask of the more general automatic music transcription, deals
with extracting drum instrument note onsets from an audio source. Recently, progress in transcription
performance has been made using non-negative matrix factorization as well as deep learning methods.
However, these works primarily focus on transcribing three drum instruments only: snare drum,
bass drum, and hi-hat. Yet, for many applications, the ability to transcribe more drum instruments
which make up standard drum kits used in western popular music would be desirable. In this work, convolutional
and convolutional recurrent neural networks are trained to transcribe a wider range of drum instruments.
First, the shortcomings of publicly available datasets in this context are discussed. To overcome
these limitations, a larger synthetic dataset is introduced. Then, methods to train models using
the new dataset focusing on generalization to real world data are investigated. Finally, the trained
models are evaluated on publicly available datasets and results are discussed. The contributions
of this work comprise: (i.) a large-scale synthetic dataset for drum transcription, (ii.) first
steps towards an automatic drum transcription system that supports a larger range of instruments
by evaluating and discussing training setups and the impact of datasets in this context, and (iii.)
a publicly available set of trained models for drum transcription. Additional materials are available
at this http URL vogl/dafx2018. 