The knowledge about the placement and appearance of lane markings is a prerequisite for the creation
of maps with high precision, necessary for autonomous driving, infrastructure monitoring, lane-wise
traffic management, and urban planning. Lane markings are one of the important components of such
maps. Lane markings convey the rules of roads to drivers. While these rules are learned by humans,
an autonomous driving vehicle should be taught to learn them to localize itself. Therefore, accurate
and reliable lane marking semantic segmentation in the imagery of roads and highways is needed to
achieve such goals. We use airborne imagery which can capture a large area in a short period of time
by introducing an aerial lane marking dataset. In this work, we propose a Symmetric Fully Convolutional
Neural Network enhanced by Wavelet Transform in order to automatically carry out lane marking segmentation
in aerial imagery. Due to a heavily unbalanced problem in terms of number of lane marking pixels compared
with background pixels, we use a customized loss function as well as a new type of data augmentation
step. We achieve a very high accuracy in pixel-wise localization of lane markings without using
3rd-party information. In this work, we introduce the first high-quality dataset used within our
experiments which contains a broad range of situations and classes of lane markings representative
of current transportation systems. This dataset will be publicly available and hence, it can be
used as the benchmark dataset for future algorithms within this domain. 