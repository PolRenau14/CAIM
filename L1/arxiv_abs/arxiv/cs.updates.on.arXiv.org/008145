Linear algebra operations are widely used in scientific computing and machine learning applications.
However, it is challenging for scientists and data analysts to run linear algebra at scales beyond
a single machine. Traditional approaches either require access to supercomputing clusters, or
impose configuration and cluster management challenges. In this paper we show how the disaggregation
of storage and compute resources in so-called "serverless" environments, combined with compute-intensive
workload characteristics, can be exploited to achieve elastic scalability and ease of management.
We present numpywren, a system for linear algebra built on a serverless architecture. We also introduce
LAmbdaPACK, a domain-specific language designed to implement highly parallel linear algebra
algorithms in a serverless setting. We show that, for certain linear algebra algorithms such as
matrix multiply, singular value decomposition, and Cholesky decomposition, numpywren's performance
(completion time) is within 33% of ScaLAPACK, and its compute efficiency (total CPU-hours) is up
to 240% better due to elasticity, while providing an easier to use interface and better fault tolerance.
At the same time, we show that the inability of serverless runtimes to exploit locality across the
cores in a machine fundamentally limits their network efficiency, which limits performance on
other algorithms such as QR factorization. This highlights how cloud providers could better support
these types of computations through small changes in their infrastructure. 