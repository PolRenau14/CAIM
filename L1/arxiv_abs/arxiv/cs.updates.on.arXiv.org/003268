Single image super resolution (SISR) is to reconstruct a high resolution image from a single low
resolution image. The SISR task has been a very attractive research topic over the last two decades.
In recent years, convolutional neural network (CNN) based models have achieved great performance
on SISR task. Despite the breakthroughs achieved by using CNN models, there are still some problems
remaining unsolved, such as how to recover high frequency details of high resolution images. Previous
CNN based models always use a pixel wise loss, such as l2 loss. Although the high resolution images
constructed by these models have high peak signal-to-noise ratio (PSNR), they often tend to be blurry
and lack high-frequency details, especially at a large scaling factor. In this paper, we build a
super resolution perceptual generative adversarial network (SRPGAN) framework for SISR tasks.
In the framework, we propose a robust perceptual loss based on the discriminator of the built SRPGAN
model. We use the Charbonnier loss function to build the content loss and combine it with the proposed
perceptual loss and the adversarial loss. Compared with other state-of-the-art methods, our method
has demonstrated great ability to construct images with sharp edges and rich details. We also evaluate
our method on different benchmarks and compare it with previous CNN based methods. The results show
that our method can achieve much higher structural similarity index (SSIM) scores on most of the
benchmarks than the previous state-of-art methods. 