Deep Convolutional Neural Networks (DCNNs) have recently been applied successfully to a variety
of vision and multimedia tasks, thus driving development of novel solutions in several application
domains. Document analysis is a particularly promising area for DCNNs: indeed, the number of available
digital documents has reached unprecedented levels, and humans are no longer able to discover and
retrieve all the information contained in these documents without the help of automation. Under
this scenario, DCNNs offers a viable solution to automate the information extraction process from
digital documents. Within the realm of information extraction from documents, detection of tables
and charts is particularly needed as they contain a visual summary of the most valuable information
contained in a document. For a complete automation of visual information extraction process from
tables and charts, it is necessary to develop techniques that localize them and identify precisely
their boundaries. In this paper we aim at solving the table/chart detection task through an approach
that combines deep convolutional neural networks, graphical models and saliency concepts. In
particular, we propose a saliency-based fully-convolutional neural network performing multi-scale
reasoning on visual cues followed by a fully-connected conditional random field (CRF) for localizing
tables and charts in digital/digitized documents. Performance analysis carried out on an extended
version of ICDAR 2013 (with annotated charts as well as tables) shows that our approach yields promising
results, outperforming existing models. 