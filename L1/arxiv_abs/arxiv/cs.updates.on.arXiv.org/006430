Advances in deep learning for natural images have prompted a surge of interest in applying similar
techniques to medical images. The majority of the initial attempts focused on replacing the input
of a deep convolutional neural network with a medical image, which does not take into consideration
the fundamental differences between these two types of images. Specifically, fine details are
necessary for detection in medical images, unlike in natural images where coarse structures matter
most. This difference makes it inadequate to use the existing network architectures developed
for natural images, because they work on heavily downscaled images to reduce the memory requirements.
This hides details necessary to make accurate predictions. Additionally, a single exam in medical
imaging often comes with a set of views which must be fused in order to reach a correct conclusion.
In our work, we propose to use a multi-view deep convolutional neural network that handles a set of
high-resolution medical images. We evaluate it on large-scale mammography-based breast cancer
screening (BI-RADS prediction) using 886,000 images. We focus on investigating the impact of the
training set size and image size on the prediction accuracy. Our results highlight that performance
increases with the size of training set, and that the best performance can only be achieved using
the original resolution. In the reader study, performed on a random subset of the test set, we confirmed
the efficacy of our model, which achieved performance comparable to a committee of radiologists
when presented with the same data. 