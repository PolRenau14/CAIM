An electroencephalography (EEG) based Brain Computer Interface (BCI) enables people to communicate
with the outside world by interpreting the EEG signals of their brains to interact with devices such
as wheelchairs and intelligent robots. More specifically, motor imagery EEG (MI-EEG), which reflects
a subjects active intent, is attracting increasing attention for a variety of BCI applications.
Accurate classification of MI-EEG signals while essential for effective operation of BCI systems,
is challenging due to the significant noise inherent in the signals and the lack of informative correlation
between the signals and brain activities. In this paper, we propose a novel deep neural network based
learning framework that affords perceptive insights into the relationship between the MI-EEG
data and brain activities. We design a joint convolutional recurrent neural network that simultaneously
learns robust high-level feature presentations through low-dimensional dense embeddings from
raw MI-EEG signals. We also employ an Autoencoder layer to eliminate various artifacts such as background
activities. The proposed approach has been evaluated extensively on a large- scale public MI-EEG
dataset and a limited but easy-to-deploy dataset collected in our lab. The results show that our
approach outperforms a series of baselines and the competitive state-of-the- art methods, yielding
a classification accuracy of 95.53%. The applicability of our proposed approach is further demonstrated
with a practical BCI system for typing. 