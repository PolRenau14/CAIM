Existing logo detection benchmarks consider artificial deployment scenarios by assuming that
large training data with fine-grained bounding box annotations for each class are available for
model training. Such assumptions are often invalid in realistic logo detection scenarios where
new logo classes come progressively and require to be detected with little or none budget for exhaustively
labelling fine-grained training data for every new class. Existing benchmarks are thus unable
to evaluate the true performance of a logo detection method in realistic and open deployments. In
this work, we introduce a more realistic and challenging logo detection setting, called Open Logo
Detection. Specifically, this new setting assumes fine-grained labelling only on a small proportion
of logo classes whilst the remaining classes have no labelled training data to simulate the open
deployment. We further create an open logo detection benchmark, called OpenLogo,to promote the
investigation of this new challenge. OpenLogo contains 27,083 images from 352 logo classes, built
by aggregating/refining 7 existing datasets and establishing an open logo detection evaluation
protocol. To address this challenge, we propose a Context Adversarial Learning (CAL) approach
to synthesising training data with coherent logo instance appearance against diverse background
context for enabling more effective optimisation of contemporary deep learning detection models.
Experiments show the performance advantage of CAL over existing state-of-the-art alternative
methods on the more realistic and challenging OpenLogo benchmark. 