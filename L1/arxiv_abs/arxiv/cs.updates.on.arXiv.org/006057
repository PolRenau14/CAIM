Reducing the use of agrochemicals is an important component towards sustainable agriculture.
Robots that can perform targeted weed control offer the potential to contribute to this goal, for
example, through specialized weeding actions such as selective spraying or mechanical weed removal.
A prerequisite of such systems is a reliable and robust plant classification system that is able
to distinguish crop and weed in the field. A major challenge in this context is the fact that different
fields show a large variability. Thus, classification systems have to robustly cope with substantial
environmental changes with respect to weed pressure and weed types, growth stages of the crop, visual
appearance, and soil conditions. In this paper, we propose a novel crop-weed classification system
that relies on a fully convolutional network with an encoder-decoder structure and incorporates
spatial information by considering image sequences. Exploiting the crop arrangement information
that is observable from the image sequences enables our system to robustly estimate a pixel-wise
labeling of the images into crop and weed, i.e., a semantic segmentation. We provide a thorough experimental
evaluation, which shows that our system generalizes well to previously unseen fields under varying
environmental conditions --- a key capability to actually use such systems in precision framing.
We provide comparisons to other state-of-the-art approaches and show that our system substantially
improves the accuracy of crop-weed classification without requiring a retraining of the model.
