We consider online linear optimization over symmetric positive semi-definite matrices, which
has various applications including the online collaborative filtering. The problem is formulated
as a repeated game between the algorithm and the adversary, where in each round t the algorithm and
the adversary choose matrices X_t and L_t, respectively, and then the algorithm suffers a loss given
by the Frobenius inner product of X_t and L_t. The goal of the algorithm is to minimize the cumulative
loss. We can employ a standard framework called Follow the Regularized Leader (FTRL) for designing
algorithms, where we need to choose an appropriate regularization function to obtain a good performance
guarantee. We show that the log-determinant regularization works better than other popular regularization
functions in the case where the loss matrices L_t are all sparse. Using this property, we show that
our algorithm achieves an optimal performance guarantee for the online collaborative filtering.
The technical contribution of the paper is to develop a new technique of deriving performance bounds
by exploiting the property of strong convexity of the log-determinant with respect to the loss matrices,
while in the previous analysis the strong convexity is defined with respect to a norm. Intuitively,
skipping the norm analysis results in the improved bound. Moreover, we apply our method to online
linear optimization over vectors and show that the FTRL with the Burg entropy regularizer, which
is the analogue of the log-determinant regularizer in the vector case, works well. 