Monocular depth estimation, which plays a crucial role in understanding 3D scene geometry, is an
ill-posed problem. Recent methods have gained significant improvement by exploring image-level
information and hierarchical features from deep convolutional neural networks (DCNNs). These
methods model depth estimation as a regression problem and train the regression networks by minimizing
mean squared error, which suffers from slow convergence and unsatisfactory local solutions. Besides,
existing depth estimation networks employ repeated spatial pooling operations, resulting in
undesirable low-resolution feature maps. To obtain high-resolution depth maps, skip-connections
or multi-layer deconvolution networks are required, which complicates network training and consumes
much more computations. To eliminate or at least largely reduce these problems, we introduce a spacing-increasing
discretization (SID) strategy to discretize depth and recast depth network learning as an ordinal
regression problem. By training the network using an ordinary regression loss, our method achieves
much higher accuracy and \dd{faster convergence in synch}. Furthermore, we adopt a multi-scale
network structure which avoids unnecessary spatial pooling and captures multi-scale information
in parallel. The method described in this paper achieves state-of-the-art results on four challenging
benchmarks, i.e., KITTI [17], ScanNet [9], Make3D [50], and NYU Depth v2 [42], and win the 1st prize
in Robust Vision Challenge 2018. Code has been made available at: https://github.com/hufu6371/DORN.
