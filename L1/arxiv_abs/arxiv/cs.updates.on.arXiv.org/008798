While several datasets for autonomous navigation have become available in recent years, they tend
to focus on structured driving environments. This usually corresponds to well-delineated infrastructure
such as lanes, a small number of well-defined categories for traffic participants, low variation
in object or background appearance and strict adherence to traffic rules. We propose IDD, a novel
dataset for road scene understanding in unstructured environments where the above assumptions
are largely not satisfied. It consists of 10,004 images, finely annotated with 34 classes collected
from 182 drive sequences on Indian roads. The label set is expanded in comparison to popular benchmarks
such as Cityscapes, to account for new classes. It also reflects label distributions of road scenes
significantly different from existing datasets, with most classes displaying greater within-class
diversity. Consistent with real driving behaviours, it also identifies new classes such as drivable
areas besides the road. We propose a new four-level label hierarchy, which allows varying degrees
of complexity and opens up possibilities for new training methods. Our empirical study provides
an in-depth analysis of the label characteristics. State-of-the-art methods for semantic segmentation
achieve much lower accuracies on our dataset, demonstrating its distinction compared to Cityscapes.
Finally, we propose that our dataset is an ideal opportunity for new problems such as domain adaptation,
few-shot learning and behaviour prediction in road scenes. 