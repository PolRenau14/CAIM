Imagine a situation where a group of adversaries is preparing an attack on the United States or U.S.
interests. An intelligence analyst has observed some signals, but the situation is rapidly changing.
The analyst faces the decision to alert a principal decision maker that an attack is imminent, or
to wait until more is known about the situation. This warning decision is based on the analyst's observation
and evaluation of signals, independent or correlated, and on her updating of the prior probabilities
of possible scenarios and their outcomes. The warning decision also depends on the analyst's assessment
of the crisis' dynamics and perception of the preferences of the principal decision maker, as well
as the lead time needed for an appropriate response. This article presents a model to support this
analyst's dynamic warning decision. As with most problems involving warning, the key is to manage
the tradeoffs between false positives and false negatives given the probabilities and the consequences
of intelligence failures of both types. The model is illustrated by revisiting the case of the attack
on Pearl Harbor in December 1941. It shows that the radio silence of the Japanese fleet carried considerable
information (Sir Arthur Conan Doyle's "dog in the night" problem), which was misinterpreted at
the time. Even though the probabilities of different attacks were relatively low, their consequences
were such that the Bayesian dynamic reasoning described here may have provided valuable information
to key decision makers. 