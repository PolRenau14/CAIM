In this work, we propose a profile matching (or deanonymization) attack for unstructured online
social networks (OSNs) in which similarity in graphical structure cannot be used for profile matching.
We consider different attributes that are publicly shared by users. Such attributes include both
obvious identifiers such as the user name and non-obvious identifiers such as interest similarity
or sentiment variation between different posts of a user in different platforms. We study the effect
of using different combinations of these attributes to the profile matching in order to show the
privacy threat in an extensive way. Our proposed framework mainly relies on machine learning techniques
and optimization algorithms. We evaluate the proposed framework on two real-life datasets that
are constructed by us. Our results indicate that profiles of the users in different OSNs can be matched
with high probability by only using publicly shared attributes and without using the underlying
graphical structure of the OSNs. We also propose possible countermeasures to mitigate this threat
in the expense of reduction in the accuracy (or utility) of the attributes shared by the users. We
formulate the tradeoff between the privacy and profile utility of the users as an optimization problem
and show how slight changes in the profiles of the users would reduce the success of the attack. We
believe that this work will be a valuable step to build a privacy-preserving tool for users against
profile matching attacks between OSNs. 