We theoretically analyze the phase sensitivity of the Induced-Coherence (Mandel-Type) Interferometer,
including the case where the sensitivity is "boosted" into the bright input regime with coherent-light
seeding. We find scaling which reaches below the shot noise limit, even when seeding the spatial
mode which does not interact with the sample - or when seeding the undetected mode. It is a hybrid of
a linear and a non-linear (Yurke-Type) interferometer, and aside from the super-sensitivity,
is distinguished from other systems by "preferring" an imbalance in the gains of the two non-linearities
(with the second gain being optimal at low values), and non-monotonic behavior of the sensitivity
as a function of the gain of the second non-linearity. Furthermore, the setup allows use of subtracted
intensity measurements, instead of direct (additive) or homodyne measurements - a significant
practical advantage. Bright, super-sensitive phase estimation of an object with different light
fields for interaction and detection is possible, with various potential applications, especially
in cases where the sample may be sensitive to light, or is most interesting in frequency domains outside
what is easily detected, or when desiring bright-light phase estimation with sensitive/delicate
detectors. We use an analysis in terms of general squeezing and discover that super-sensitivity
occurs only in this case - that is, the effect is not present with the spontaneous-parametric-down-conversion
approximation, which many previous analyses and experiments have focused on. 